services:
  build-args:
    build:
      args:
        BASE_IMAGE: localhost/vllm:v0.9.0.1-apertus-vllm
        # vLLM custom-build from ./build-vllm/Dockerfile-apertus-vllm
        # Bsed on the nvcr.io/nvidia/pytorch:25.02-py3
        # With  Python 3.12. Pytorch 2.7.0a0+ecf3bae40a.nv25.2
        # https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-25-0.2.html
        # https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch
        GIT_IMAGE: docker.io/alpine/git:2.40.1            # https://hub.docker.com/r/alpine/git/tags
        # You can find the entrypoint by running `docker inspect BASE_IMAGE | grep -A 3 Entrypoint`
        # If there is no entrypoint, you can leave it empty.
        BASE_ENTRYPOINT: /opt/nvidia/nvidia_entrypoint.sh
        # 1 normally, 0 if the entrypoint does not exec its arguments, in rare cases.
        BASE_ENTRYPOINT_EXECS: 1

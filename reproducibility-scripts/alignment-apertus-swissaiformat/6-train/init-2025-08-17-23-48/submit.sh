sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-8b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus8B-tokens10.2T-it2059810-newcooldown-apertus-sft-mixture-7-ln-v2-ademamix/checkpoints/7fea1f8c44336360/checkpoint-8925' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-8b-sft-10T-mixture-7-7fea1f8c44336360-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 7:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-17-23-48/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_preference accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=2 training_args.per_device_train_batch_size=1 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0 wandb.run_name=first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,first-sweep]' artifacts_subdir=shared resuming.resume=True

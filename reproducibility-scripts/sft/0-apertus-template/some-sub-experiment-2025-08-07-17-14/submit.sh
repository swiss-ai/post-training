sbatch -N 64 -p large512 -t 48:00:00 -o reproducibility-scripts/sft/0-apertus-template/some-sub-experiment-2025-08-07-17-14/out/Apertus8B-tokens7.2T-it1728000-hotfix-apertus-sft-mixture-1-bs512-lr5e-06-epochs1-adamw_torch.out -e reproducibility-scripts/sft/0-apertus-template/some-sub-experiment-2025-08-07-17-14/out/Apertus8B-tokens7.2T-it1728000-hotfix-apertus-sft-mixture-1-bs512-lr5e-06-epochs1-adamw_torch.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=apertus-sft-mixture-1 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-06 tokenizer_args.chat_template_name=tulu training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=0-apertus-template/Apertus8B-tokens7.2T-it1728000-hotfix-apertus-sft-mixture-1-bs512-lr5e-06-epochs1-adamw_torch wandb.run_name=0-apertus-template/Apertus8B-tokens7.2T-it1728000-hotfix-apertus-sft-mixture-1-bs512-lr5e-06-epochs1-adamw_torch wandb.tags=[prod,plw,default,0-apertus-template] resuming.resume=True
sbatch -N 64 -p large512 -t 48:00:00 -o reproducibility-scripts/sft/0-apertus-template/some-sub-experiment-2025-08-07-17-14/out/Apertus70B-tokens15T-it1155828-apertus-sft-mixture-1-bs512-lr2e-06-epochs1-adamw_torch.out -e reproducibility-scripts/sft/0-apertus-template/some-sub-experiment-2025-08-07-17-14/out/Apertus70B-tokens15T-it1155828-apertus-sft-mixture-1-bs512-lr2e-06-epochs1-adamw_torch.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=apertus-sft-mixture-1 model=apertus-70b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus70B-tokens15T-it1155828 tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus70B-tokens15T-it1155828 trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero3.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=2e-06 tokenizer_args.chat_template_name=tulu training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=0-apertus-template/Apertus70B-tokens15T-it1155828-apertus-sft-mixture-1-bs512-lr2e-06-epochs1-adamw_torch wandb.run_name=0-apertus-template/Apertus70B-tokens15T-it1155828-apertus-sft-mixture-1-bs512-lr2e-06-epochs1-adamw_torch wandb.tags=[prod,plw,default,0-apertus-template] resuming.resume=True
